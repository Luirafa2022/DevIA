"sqlite3" --- Interface DB-API 2.0 para bancos de dados SQLite
**************************************************************

**Código-fonte:** Lib/sqlite3/

SQLite é uma biblioteca C que fornece um banco de dados leve baseado
em disco que não requer um processo de servidor separado e permite
acessar o banco de dados usando uma variante não padrão da linguagem
de consulta SQL. Algumas aplicações podem usar SQLite para
armazenamento interno de dados. Também é possível prototipar uma
aplicação usando SQLite e, em seguida, portar o código para um banco
de dados maior, como PostgreSQL ou Oracle.

O módulo "sqlite3" foi escrito por Gerhard Häring. Ele fornece uma
interface SQL compatível com a especificação DB-API 2.0 descrita pela
**PEP 249** e requer SQLite 3.7.15 ou mais recente.

Esse documento inclui quatro seções principais:

* Tutorial ensina como usar o módulo "sqlite3".

* Referência descreve as classes e funções que este módulo define.

* Guias de como fazer detalha como lidar com tarefas específicas.

* Explicação fornece informações detalhadas sobre controle de
  transações.

Ver também:

  https://www.sqlite.org
     A página web do SQLite; a documentação descreve a sintaxe e os
     tipos de dados disponíveis para o dialeto SQL suportado.

  https://www.w3schools.com/sql/
     Tutoriais, referências e exemplos para aprender a sintaxe SQL.

  **PEP 249** - Especificação 2.0 da API de banco de dados
     PEP escrita por Marc-André Lemburg.


Tutorial
========

Neste tutorial, você criará um banco de dados de filmes do Monty
Python usando a funcionalidade básica "sqlite3". Ele pressupõe uma
compreensão fundamental dos conceitos de banco de dados, incluindo
cursores e transações.

Primeiro, precisamos criar um novo banco de dados e abrir uma conexão
com o banco de dados para permitir que "sqlite3" funcione com ele.
Chame "sqlite3.connect()" para criar uma conexão com o banco de dados
"tutorial.db" no diretório de trabalho atual, criando-o implicitamente
se ele não existir:

   import sqlite3
   con = sqlite3.connect("tutorial.db")

O objeto "Connection" "con" retornado representa a conexão com o banco
de dados em disco.

Para executar instruções SQL e buscar resultados de consultas SQL,
precisaremos usar um cursor de banco de dados. Chame "con.cursor()"
para criar o "Cursor":

   cur = con.cursor()

Agora que temos uma conexão com o banco de dados e um cursor, podemos
criar uma tabela de banco de dados "movie" com colunas para título,
ano de lançamento e pontuação da revisão. Para simplificar, podemos
apenas usar nomes de colunas na declaração da tabela - graças ao
recurso tipagem flexível do SQLite, especificar os tipos de dados é
opcional. Execute a instrução "CREATE TABLE" chamando
"cur.execute(...)":

   cur.execute("CREATE TABLE movie(title, year, score)")

Podemos verificar se a nova tabela foi criada consultando a tabela
embutida "sqlite_master" no SQLite, que agora deve conter uma entrada
para a definição da tabela "movie" (veja The Schema Table para
detalhes). Execute essa consulta chamando "cur.execute(...)", atribua
o resultado a "res" e chame "res.fetchone()" para buscar a linha
resultante:

   >>> res = cur.execute("SELECT name FROM sqlite_master")
   >>> res.fetchone()
   ('movie',)

Podemos ver que a tabela foi criada, pois a consulta retorna uma
"tuple" contendo o nome da tabela. Se consultarmos "sqlite_master" por
uma tabela inexistente "spam", "res.fetchone()" retornará "None":

   >>> res = cur.execute("SELECT name FROM sqlite_master WHERE name='spam'")
   >>> res.fetchone() is None
   True

Agora, adicione duas linhas de dados fornecidos como literais SQL
executando uma instrução "INSERT", mais uma vez chamando
"cur.execute(...)":

   cur.execute("""
       INSERT INTO movie VALUES
           ('Monty Python and the Holy Grail', 1975, 8.2),
           ('And Now for Something Completely Different', 1971, 7.5)
   """)

A instrução "INSERT" abre implicitamente uma transação, que precisa
ser confirmada antes que as alterações sejam salvas no banco de dados
(veja Controle de transações para detalhes). Chame "con.commit()" no
objeto de conexão para confirmar a transação:

   con.commit()

Podemos verificar que os dados foram inseridos corretamente executando
uma consulta "SELECT". Use o já conhecido "cur.execute(...)" para
atribuir o resultado a "res" e chame "res.fetchall()" para retornar
todas as linhas resultantes.

   >>> res = cur.execute("SELECT score FROM movie")
   >>> res.fetchall()
   [(8.2,), (7.5,)]

O resultado é uma "list" de duas "tuple"s, uma por linha, cada uma
contendo o valor "score" dessa linha.

Agora, insira mais três linhas chamando "cur.executemany(...)":

   data = [
       ("Monty Python Live at the Hollywood Bowl", 1982, 7.9),
       ("Monty Python's The Meaning of Life", 1983, 7.5),
       ("Monty Python's Life of Brian", 1979, 8.0),
   ]
   cur.executemany("INSERT INTO movie VALUES(?, ?, ?)", data)
   con.commit()  # Remember to commit the transaction after executing INSERT.

Observe que espaços reservados "?" são usados para vincular "data" à
consulta. Sempre use espaços reservados em vez de formatação de string
para vincular valores Python a instruções SQL, para evitar ataques de
injeção de SQL (consulte How to use placeholders to bind values in SQL
queries para mais detalhes).

Podemos verificar que as novas linhas foram inseridas executando uma
consulta "SELECT", desta vez iterando sobre os resultados da consulta.

   >>> for row in cur.execute("SELECT year, title FROM movie ORDER BY year"):
   ...     print(row)
   (1971, 'And Now for Something Completely Different')
   (1975, 'Monty Python and the Holy Grail')
   (1979, "Monty Python's Life of Brian")
   (1982, 'Monty Python Live at the Hollywood Bowl')
   (1983, "Monty Python's The Meaning of Life")

Cada linha é uma "tuple" de dois itens "(year, title)", correspondendo
às colunas selecionadas na consulta.

Finalmente, verifique se o banco de dados foi gravado no disco
chamando "con.close()" para fechar a conexão existente, abrir uma
nova, criar um novo cursor e, em seguida, consultar o banco de dados.

   >>> con.close()
   >>> new_con = sqlite3.connect("tutorial.db")
   >>> new_cur = new_con.cursor()
   >>> res = new_cur.execute("SELECT title, year FROM movie ORDER BY score DESC")
   >>> title, year = res.fetchone()
   >>> print(f'The highest scoring Monty Python movie is {title!r}, released in {year}')
   The highest scoring Monty Python movie is 'Monty Python and the Holy Grail', released in 1975

Você agora criou um banco de dados SQLite usando o módulo "sqlite3",
inseriu dados e recuperou valores dele de várias maneiras.

Ver também:

  * Guias de como fazer para leitura adicional:

    * How to use placeholders to bind values in SQL queries

    * How to adapt custom Python types to SQLite values

    * How to convert SQLite values to custom Python types

    * How to use the connection context manager

    * How to create and use row factories

  * Explicação para obter informações detalhadas sobre o controle de
    transações.


Referência
==========


Module functions
----------------

sqlite3.connect(database, timeout=5.0, detect_types=0, isolation_level='DEFERRED', check_same_thread=True, factory=sqlite3.Connection, cached_statements=128, uri=False, *, autocommit=sqlite3.LEGACY_TRANSACTION_CONTROL)

   Open a connection to an SQLite database.

   Parâmetros:
      * **database** (*path-like object*) -- The path to the database
        file to be opened. You can pass "":memory:"" to create an
        SQLite database existing only in memory, and open a connection
        to it.

      * **timeout** (*float*) -- How many seconds the connection
        should wait before raising an "OperationalError" when a table
        is locked. If another connection opens a transaction to modify
        a table, that table will be locked until the transaction is
        committed. Default five seconds.

      * **detect_types** (*int*) -- Control whether and how data types
        not natively supported by SQLite are looked up to be converted
        to Python types, using the converters registered with
        "register_converter()". Set it to any combination (using "|",
        bitwise or) of "PARSE_DECLTYPES" and "PARSE_COLNAMES" to
        enable this. Column names takes precedence over declared types
        if both flags are set. Types cannot be detected for generated
        fields (for example "max(data)"), even when the *detect_types*
        parameter is set; "str" will be returned instead. By default
        ("0"), type detection is disabled.

      * **isolation_level** (*str** | **None*) -- Control legacy
        transaction handling behaviour. See
        "Connection.isolation_level" and Controle de transação através
        do atributo isolation_level for more information. Can be
        ""DEFERRED"" (default), ""EXCLUSIVE"" or ""IMMEDIATE""; or
        "None" to disable opening transactions implicitly. Has no
        effect unless "Connection.autocommit" is set to
        "LEGACY_TRANSACTION_CONTROL" (the default).

      * **check_same_thread** (*bool*) -- If "True" (default),
        "ProgrammingError" will be raised if the database connection
        is used by a thread other than the one that created it. If
        "False", the connection may be accessed in multiple threads;
        write operations may need to be serialized by the user to
        avoid data corruption. See "threadsafety" for more
        information.

      * **factory** (*Connection*) -- A custom subclass of
        "Connection" to create the connection with, if not the default
        "Connection" class.

      * **cached_statements** (*int*) -- The number of statements that
        "sqlite3" should internally cache for this connection, to
        avoid parsing overhead. By default, 128 statements.

      * **uri** (*bool*) -- If set to "True", *database* is
        interpreted as a URI (Uniform Resource Identifier) with a file
        path and an optional query string. The scheme part *must* be
        ""file:"", and the path can be relative or absolute. The query
        string allows passing parameters to SQLite, enabling various
        How to work with SQLite URIs.

      * **autocommit** (*bool*) -- Control **PEP 249** transaction
        handling behaviour. See "Connection.autocommit" and Controle
        de transações através do atributo autocommit for more
        information. *autocommit* currently defaults to
        "LEGACY_TRANSACTION_CONTROL". The default will change to
        "False" in a future Python release.

   Tipo de retorno:
      *Connection*

   Raises an auditing event "sqlite3.connect" with argument
   "database".

   Raises an auditing event "sqlite3.connect/handle" with argument
   "connection_handle".

   Alterado na versão 3.4: Adicionado o parâmetro *uri*.

   Alterado na versão 3.7: *database* can now also be a *path-like
   object*, not only a string.

   Alterado na versão 3.10: Added the "sqlite3.connect/handle"
   auditing event.

   Alterado na versão 3.12: Added the *autocommit* parameter.

sqlite3.complete_statement(statement)

   Return "True" if the string *statement* appears to contain one or
   more complete SQL statements. No syntactic verification or parsing
   of any kind is performed, other than checking that there are no
   unclosed string literals and the statement is terminated by a
   semicolon.

   Por exemplo:

      >>> sqlite3.complete_statement("SELECT foo FROM bar;")
      True
      >>> sqlite3.complete_statement("SELECT foo")
      False

   This function may be useful during command-line input to determine
   if the entered text seems to form a complete SQL statement, or if
   additional input is needed before calling "execute()".

   See "runsource()" in Lib/sqlite3/__main__.py for real-world use.

sqlite3.enable_callback_tracebacks(flag, /)

   Enable or disable callback tracebacks. By default you will not get
   any tracebacks in user-defined functions, aggregates, converters,
   authorizer callbacks etc. If you want to debug them, you can call
   this function with *flag* set to "True". Afterwards, you will get
   tracebacks from callbacks on "sys.stderr". Use "False" to disable
   the feature again.

   Register an "unraisable hook handler" for an improved debug
   experience:

      >>> sqlite3.enable_callback_tracebacks(True)
      >>> con = sqlite3.connect(":memory:")
      >>> def evil_trace(stmt):
      ...     5/0
      ...
      >>> con.set_trace_callback(evil_trace)
      >>> def debug(unraisable):
      ...     print(f"{unraisable.exc_value!r} in callback {unraisable.object.__name__}")
      ...     print(f"Error message: {unraisable.err_msg}")
      >>> import sys
      >>> sys.unraisablehook = debug
      >>> cur = con.execute("SELECT 1")
      ZeroDivisionError('division by zero') in callback evil_trace
      Error message: None

sqlite3.register_adapter(type, adapter, /)

   Register an *adapter* *callable* to adapt the Python type *type*
   into an SQLite type. The adapter is called with a Python object of
   type *type* as its sole argument, and must return a value of a type
   that SQLite natively understands.

sqlite3.register_converter(typename, converter, /)

   Register the *converter* *callable* to convert SQLite objects of
   type *typename* into a Python object of a specific type. The
   converter is invoked for all SQLite values of type *typename*; it
   is passed a "bytes" object and should return an object of the
   desired Python type. Consult the parameter *detect_types* of
   "connect()" for information regarding how type detection works.

   Note: *typename* and the name of the type in your query are matched
   case-insensitively.


Constantes do módulo
--------------------

sqlite3.LEGACY_TRANSACTION_CONTROL

   Set "autocommit" to this constant to select old style (pre-Python
   3.12) transaction control behaviour. See Controle de transação
   através do atributo isolation_level for more information.

sqlite3.PARSE_COLNAMES

   Pass this flag value to the *detect_types* parameter of "connect()"
   to look up a converter function by using the type name, parsed from
   the query column name, as the converter dictionary key. The type
   name must be wrapped in square brackets ("[]").

      SELECT p as "p [point]" FROM test;  ! will look up converter "point"

   This flag may be combined with "PARSE_DECLTYPES" using the "|"
   (bitwise or) operator.

sqlite3.PARSE_DECLTYPES

   Pass this flag value to the *detect_types* parameter of "connect()"
   to look up a converter function using the declared types for each
   column. The types are declared when the database table is created.
   "sqlite3" will look up a converter function using the first word of
   the declared type as the converter dictionary key. For example:

      CREATE TABLE test(
         i integer primary key,  ! will look up a converter named "integer"
         p point,                ! will look up a converter named "point"
         n number(10)            ! will look up a converter named "number"
       )

   This flag may be combined with "PARSE_COLNAMES" using the "|"
   (bitwise or) operator.

sqlite3.SQLITE_OK
sqlite3.SQLITE_DENY
sqlite3.SQLITE_IGNORE

   Flags that should be returned by the *authorizer_callback*
   *callable* passed to "Connection.set_authorizer()", to indicate
   whether:

   * Access is allowed ("SQLITE_OK"),

   * The SQL statement should be aborted with an error ("SQLITE_DENY")

   * The column should be treated as a "NULL" value ("SQLITE_IGNORE")

sqlite3.apilevel

   String constant stating the supported DB-API level. Required by the
   DB-API. Hard-coded to ""2.0"".

sqlite3.paramstyle

   String constant stating the type of parameter marker formatting
   expected by the "sqlite3" module. Required by the DB-API. Hard-
   coded to ""qmark"".

   Nota:

     The "named" DB-API parameter style is also supported.

sqlite3.sqlite_version

   Version number of the runtime SQLite library as a "string".

sqlite3.sqlite_version_info

   Version number of the runtime SQLite library as a "tuple" of
   "integers".

sqlite3.threadsafety

   Integer constant required by the DB-API 2.0, stating the level of
   thread safety the "sqlite3" module supports. This attribute is set
   based on the default threading mode the underlying SQLite library
   is compiled with. The SQLite threading modes are:

   1. **Single-thread**: In this mode, all mutexes are disabled and
      SQLite is unsafe to use in more than a single thread at once.

   2. **Multi-thread**: In this mode, SQLite can be safely used by
      multiple threads provided that no single database connection is
      used simultaneously in two or more threads.

   3. **Serialized**: In serialized mode, SQLite can be safely used by
      multiple threads with no restriction.

   The mappings from SQLite threading modes to DB-API 2.0 threadsafety
   levels are as follows:

   +--------------------+-------------------+------------------------+---------------------------------+
   | SQLite threading   | threadsafety      | SQLITE_THREADSAFE      | DB-API 2.0 meaning              |
   | mode               |                   |                        |                                 |
   |====================|===================|========================|=================================|
   | single-thread      | 0                 | 0                      | Threads may not share the       |
   |                    |                   |                        | module                          |
   +--------------------+-------------------+------------------------+---------------------------------+
   | multi-thread       | 1                 | 2                      | Threads may share the module,   |
   |                    |                   |                        | but not connections             |
   +--------------------+-------------------+------------------------+---------------------------------+
   | serialized         | 3                 | 1                      | Threads may share the module,   |
   |                    |                   |                        | connections and cursors         |
   +--------------------+-------------------+------------------------+---------------------------------+

   Alterado na versão 3.11: Set *threadsafety* dynamically instead of
   hard-coding it to "1".

sqlite3.version

   Version number of this module as a "string". This is not the
   version of the SQLite library.

   Descontinuado desde a versão 3.12, será removido na versão 3.14:
   This constant used to reflect the version number of the "pysqlite"
   package, a third-party library which used to upstream changes to
   "sqlite3". Today, it carries no meaning or practical value.

sqlite3.version_info

   Version number of this module as a "tuple" of "integers". This is
   not the version of the SQLite library.

   Descontinuado desde a versão 3.12, será removido na versão 3.14:
   This constant used to reflect the version number of the "pysqlite"
   package, a third-party library which used to upstream changes to
   "sqlite3". Today, it carries no meaning or practical value.

sqlite3.SQLITE_DBCONFIG_DEFENSIVE
sqlite3.SQLITE_DBCONFIG_DQS_DDL
sqlite3.SQLITE_DBCONFIG_DQS_DML
sqlite3.SQLITE_DBCONFIG_ENABLE_FKEY
sqlite3.SQLITE_DBCONFIG_ENABLE_FTS3_TOKENIZER
sqlite3.SQLITE_DBCONFIG_ENABLE_LOAD_EXTENSION
sqlite3.SQLITE_DBCONFIG_ENABLE_QPSG
sqlite3.SQLITE_DBCONFIG_ENABLE_TRIGGER
sqlite3.SQLITE_DBCONFIG_ENABLE_VIEW
sqlite3.SQLITE_DBCONFIG_LEGACY_ALTER_TABLE
sqlite3.SQLITE_DBCONFIG_LEGACY_FILE_FORMAT
sqlite3.SQLITE_DBCONFIG_NO_CKPT_ON_CLOSE
sqlite3.SQLITE_DBCONFIG_RESET_DATABASE
sqlite3.SQLITE_DBCONFIG_TRIGGER_EQP
sqlite3.SQLITE_DBCONFIG_TRUSTED_SCHEMA
sqlite3.SQLITE_DBCONFIG_WRITABLE_SCHEMA

   These constants are used for the "Connection.setconfig()" and
   "getconfig()" methods.

   The availability of these constants varies depending on the version
   of SQLite Python was compiled with.

   Novo na versão 3.12.

   Ver também:

     https://www.sqlite.org/c3ref/c_dbconfig_defensive.html
        SQLite docs: Database Connection Configuration Options


Connection objects
------------------

class sqlite3.Connection

   Each open SQLite database is represented by a "Connection" object,
   which is created using "sqlite3.connect()". Their main purpose is
   creating "Cursor" objects, and Controle de transações.

   Ver também:

     * How to use connection shortcut methods

     * How to use the connection context manager

   An SQLite database connection has the following attributes and
   methods:

   cursor(factory=Cursor)

      Create and return a "Cursor" object. The cursor method accepts a
      single optional parameter *factory*. If supplied, this must be a
      *callable* returning an instance of "Cursor" or its subclasses.

   blobopen(table, column, row, /, *, readonly=False, name='main')

      Open a "Blob" handle to an existing BLOB (Binary Large OBject).

      Parâmetros:
         * **table** (*str*) -- The name of the table where the blob
           is located.

         * **column** (*str*) -- The name of the column where the blob
           is located.

         * **row** (*str*) -- The name of the row where the blob is
           located.

         * **readonly** (*bool*) -- Set to "True" if the blob should
           be opened without write permissions. Defaults to "False".

         * **name** (*str*) -- The name of the database where the blob
           is located. Defaults to ""main"".

      Levanta:
         **OperationalError** -- When trying to open a blob in a
         "WITHOUT ROWID" table.

      Tipo de retorno:
         Blob

      Nota:

        The blob size cannot be changed using the "Blob" class. Use
        the SQL function "zeroblob" to create a blob with a fixed
        size.

      Novo na versão 3.11.

   commit()

      Commit any pending transaction to the database. If "autocommit"
      is "True", or there is no open transaction, this method does
      nothing. If "autocommit" is "False", a new transaction is
      implicitly opened if a pending transaction was committed by this
      method.

   rollback()

      Roll back to the start of any pending transaction. If
      "autocommit" is "True", or there is no open transaction, this
      method does nothing. If "autocommit" is "False", a new
      transaction is implicitly opened if a pending transaction was
      rolled back by this method.

   close()

      Close the database connection. If "autocommit" is "False", any
      pending transaction is implicitly rolled back. If "autocommit"
      is "True" or "LEGACY_TRANSACTION_CONTROL", no implicit
      transaction control is executed. Make sure to "commit()" before
      closing to avoid losing pending changes.

   execute(sql, parameters=(), /)

      Create a new "Cursor" object and call "execute()" on it with the
      given *sql* and *parameters*. Return the new cursor object.

   executemany(sql, parameters, /)

      Create a new "Cursor" object and call "executemany()" on it with
      the given *sql* and *parameters*. Return the new cursor object.

   executescript(sql_script, /)

      Create a new "Cursor" object and call "executescript()" on it
      with the given *sql_script*. Return the new cursor object.

   create_function(name, narg, func, *, deterministic=False)

      Create or remove a user-defined SQL function.

      Parâmetros:
         * **name** (*str*) -- O nome da função SQL.

         * **narg** (*int*) -- The number of arguments the SQL
           function can accept. If "-1", it may take any number of
           arguments.

         * **func** (*callback* | None) -- A *callable* that is called
           when the SQL function is invoked. The callable must return
           a type natively supported by SQLite. Set to "None" to
           remove an existing SQL function.

         * **deterministic** (*bool*) -- If "True", the created SQL
           function is marked as deterministic, which allows SQLite to
           perform additional optimizations.

      Levanta:
         **NotSupportedError** -- If *deterministic* is used with
         SQLite versions older than 3.8.3.

      Alterado na versão 3.8: Added the *deterministic* parameter.

      Exemplo:

         >>> import hashlib
         >>> def md5sum(t):
         ...     return hashlib.md5(t).hexdigest()
         >>> con = sqlite3.connect(":memory:")
         >>> con.create_function("md5", 1, md5sum)
         >>> for row in con.execute("SELECT md5(?)", (b"foo",)):
         ...     print(row)
         ('acbd18db4cc2f85cedef654fccc4a4d8',)

   create_aggregate(name, n_arg, aggregate_class)

      Create or remove a user-defined SQL aggregate function.

      Parâmetros:
         * **name** (*str*) -- The name of the SQL aggregate function.

         * **n_arg** (*int*) -- The number of arguments the SQL
           aggregate function can accept. If "-1", it may take any
           number of arguments.

         * **aggregate_class** (*class* | None) --

           Uma classe deve implementar os seguintes métodos:

           * "step()": Add a row to the aggregate.

           * "finalize()": Return the final result of the aggregate as
             a type natively supported by SQLite.

           The number of arguments that the "step()" method must
           accept is controlled by *n_arg*.

           Set to "None" to remove an existing SQL aggregate function.

      Exemplo:

         class MySum:
             def __init__(self):
                 self.count = 0

             def step(self, value):
                 self.count += value

             def finalize(self):
                 return self.count

         con = sqlite3.connect(":memory:")
         con.create_aggregate("mysum", 1, MySum)
         cur = con.execute("CREATE TABLE test(i)")
         cur.execute("INSERT INTO test(i) VALUES(1)")
         cur.execute("INSERT INTO test(i) VALUES(2)")
         cur.execute("SELECT mysum(i) FROM test")
         print(cur.fetchone()[0])

         con.close()

   create_window_function(name, num_params, aggregate_class, /)

      Create or remove a user-defined aggregate window function.

      Parâmetros:
         * **name** (*str*) -- The name of the SQL aggregate window
           function to create or remove.

         * **num_params** (*int*) -- The number of arguments the SQL
           aggregate window function can accept. If "-1", it may take
           any number of arguments.

         * **aggregate_class** (*class* | None) --

           Uma classe que deve implementar os seguintes métodos:

           * "step()": Add a row to the current window.

           * "value()": Return the current value of the aggregate.

           * "inverse()": Remove a row from the current window.

           * "finalize()": Return the final result of the aggregate as
             a type natively supported by SQLite.

           The number of arguments that the "step()" and "value()"
           methods must accept is controlled by *num_params*.

           Set to "None" to remove an existing SQL aggregate window
           function.

      Levanta:
         **NotSupportedError** -- If used with a version of SQLite
         older than 3.25.0, which does not support aggregate window
         functions.

      Novo na versão 3.11.

      Exemplo:

         # Example taken from https://www.sqlite.org/windowfunctions.html#udfwinfunc
         class WindowSumInt:
             def __init__(self):
                 self.count = 0

             def step(self, value):
                 """Add a row to the current window."""
                 self.count += value

             def value(self):
                 """Return the current value of the aggregate."""
                 return self.count

             def inverse(self, value):
                 """Remove a row from the current window."""
                 self.count -= value

             def finalize(self):
                 """Return the final value of the aggregate.

                 Any clean-up actions should be placed here.
                 """
                 return self.count


         con = sqlite3.connect(":memory:")
         cur = con.execute("CREATE TABLE test(x, y)")
         values = [
             ("a", 4),
             ("b", 5),
             ("c", 3),
             ("d", 8),
             ("e", 1),
         ]
         cur.executemany("INSERT INTO test VALUES(?, ?)", values)
         con.create_window_function("sumint", 1, WindowSumInt)
         cur.execute("""
             SELECT x, sumint(y) OVER (
                 ORDER BY x ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING
             ) AS sum_y
             FROM test ORDER BY x
         """)
         print(cur.fetchall())

   create_collation(name, callable, /)

      Create a collation named *name* using the collating function
      *callable*. *callable* is passed two "string" arguments, and it
      should return an "integer":

      * "1" if the first is ordered higher than the second

      * "-1" if the first is ordered lower than the second

      * "0" if they are ordered equal

      The following example shows a reverse sorting collation:

         def collate_reverse(string1, string2):
             if string1 == string2:
                 return 0
             elif string1 < string2:
                 return 1
             else:
                 return -1

         con = sqlite3.connect(":memory:")
         con.create_collation("reverse", collate_reverse)

         cur = con.execute("CREATE TABLE test(x)")
         cur.executemany("INSERT INTO test(x) VALUES(?)", [("a",), ("b",)])
         cur.execute("SELECT x FROM test ORDER BY x COLLATE reverse")
         for row in cur:
             print(row)
         con.close()

      Remove a collation function by setting *callable* to "None".

      Alterado na versão 3.11: The collation name can contain any
      Unicode character.  Earlier, only ASCII characters were allowed.

   interrupt()

      Call this method from a different thread to abort any queries
      that might be executing on the connection. Aborted queries will
      raise an "OperationalError".

   set_authorizer(authorizer_callback)

      Register *callable* *authorizer_callback* to be invoked for each
      attempt to access a column of a table in the database. The
      callback should return one of "SQLITE_OK", "SQLITE_DENY", or
      "SQLITE_IGNORE" to signal how access to the column should be
      handled by the underlying SQLite library.

      The first argument to the callback signifies what kind of
      operation is to be authorized. The second and third argument
      will be arguments or "None" depending on the first argument. The
      4th argument is the name of the database ("main", "temp", etc.)
      if applicable. The 5th argument is the name of the inner-most
      trigger or view that is responsible for the access attempt or
      "None" if this access attempt is directly from input SQL code.

      Please consult the SQLite documentation about the possible
      values for the first argument and the meaning of the second and
      third argument depending on the first one. All necessary
      constants are available in the "sqlite3" module.

      Passing "None" as *authorizer_callback* will disable the
      authorizer.

      Alterado na versão 3.11: Added support for disabling the
      authorizer using "None".

   set_progress_handler(progress_handler, n)

      Register *callable* *progress_handler* to be invoked for every
      *n* instructions of the SQLite virtual machine. This is useful
      if you want to get called from SQLite during long-running
      operations, for example to update a GUI.

      If you want to clear any previously installed progress handler,
      call the method with "None" for *progress_handler*.

      Returning a non-zero value from the handler function will
      terminate the currently executing query and cause it to raise a
      "DatabaseError" exception.

   set_trace_callback(trace_callback)

      Register *callable* *trace_callback* to be invoked for each SQL
      statement that is actually executed by the SQLite backend.

      The only argument passed to the callback is the statement (as
      "str") that is being executed. The return value of the callback
      is ignored. Note that the backend does not only run statements
      passed to the "Cursor.execute()" methods.  Other sources include
      the transaction management of the "sqlite3" module and the
      execution of triggers defined in the current database.

      Passing "None" as *trace_callback* will disable the trace
      callback.

      Nota:

        Exceptions raised in the trace callback are not propagated. As
        a development and debugging aid, use
        "enable_callback_tracebacks()" to enable printing tracebacks
        from exceptions raised in the trace callback.

      Novo na versão 3.3.

   enable_load_extension(enabled, /)

      Enable the SQLite engine to load SQLite extensions from shared
      libraries if *enabled* is "True"; else, disallow loading SQLite
      extensions. SQLite extensions can define new functions,
      aggregates or whole new virtual table implementations.  One
      well-known extension is the fulltext-search extension
      distributed with SQLite.

      Nota:

        The "sqlite3" module is not built with loadable extension
        support by default, because some platforms (notably macOS)
        have SQLite libraries which are compiled without this feature.
        To get loadable extension support, you must pass the "--
        enable-loadable-sqlite-extensions" option to **configure**.

      Raises an auditing event "sqlite3.enable_load_extension" with
      arguments "connection", "enabled".

      Novo na versão 3.2.

      Alterado na versão 3.10: Added the
      "sqlite3.enable_load_extension" auditing event.

         con.enable_load_extension(True)

         # Load the fulltext search extension
         con.execute("select load_extension('./fts3.so')")

         # alternatively you can load the extension using an API call:
         # con.load_extension("./fts3.so")

         # disable extension loading again
         con.enable_load_extension(False)

         # example from SQLite wiki
         con.execute("CREATE VIRTUAL TABLE recipe USING fts3(name, ingredients)")
         con.executescript("""
             INSERT INTO recipe (name, ingredients) VALUES('broccoli stew', 'broccoli peppers cheese tomatoes');
             INSERT INTO recipe (name, ingredients) VALUES('pumpkin stew', 'pumpkin onions garlic celery');
             INSERT INTO recipe (name, ingredients) VALUES('broccoli pie', 'broccoli cheese onions flour');
             INSERT INTO recipe (name, ingredients) VALUES('pumpkin pie', 'pumpkin sugar flour butter');
             """)
         for row in con.execute("SELECT rowid, name, ingredients FROM recipe WHERE name MATCH 'pie'"):
             print(row)

         con.close()

   load_extension(path, /, *, entrypoint=None)

      Load an SQLite extension from a shared library. Enable extension
      loading with "enable_load_extension()" before calling this
      method.

      Parâmetros:
         * **path** (*str*) -- The path to the SQLite extension.

         * **entrypoint** (*str** | **None*) -- Entry point name. If
           "None" (the default), SQLite will come up with an entry
           point name of its own; see the SQLite docs Loading an
           Extension for details.

      Raises an auditing event "sqlite3.load_extension" with arguments
      "connection", "path".

      Novo na versão 3.2.

      Alterado na versão 3.10: Added the "sqlite3.load_extension"
      auditing event.

      Alterado na versão 3.12: Added the *entrypoint* parameter.

   iterdump()

      Return an *iterator* to dump the database as SQL source code.
      Useful when saving an in-memory database for later restoration.
      Similar to the ".dump" command in the **sqlite3** shell.

      Exemplo:

         # Convert file example.db to SQL dump file dump.sql
         con = sqlite3.connect('example.db')
         with open('dump.sql', 'w') as f:
             for line in con.iterdump():
                 f.write('%s\n' % line)
         con.close()

      Ver também: How to handle non-UTF-8 text encodings

   backup(target, *, pages=-1, progress=None, name='main', sleep=0.250)

      Create a backup of an SQLite database.

      Works even if the database is being accessed by other clients or
      concurrently by the same connection.

      Parâmetros:
         * **target** (*Connection*) -- The database connection to
           save the backup to.

         * **pages** (*int*) -- The number of pages to copy at a time.
           If equal to or less than "0", the entire database is copied
           in a single step. Defaults to "-1".

         * **progress** (*callback* | None) -- If set to a *callable*,
           it is invoked with three integer arguments for every backup
           iteration: the *status* of the last iteration, the
           *remaining* number of pages still to be copied, and the
           *total* number of pages. Defaults to "None".

         * **name** (*str*) -- The name of the database to back up.
           Either ""main"" (the default) for the main database,
           ""temp"" for the temporary database, or the name of a
           custom database as attached using the "ATTACH DATABASE" SQL
           statement.

         * **sleep** (*float*) -- The number of seconds to sleep
           between successive attempts to back up remaining pages.

      Example 1, copy an existing database into another:

         def progress(status, remaining, total):
             print(f'Copied {total-remaining} of {total} pages...')

         src = sqlite3.connect('example.db')
         dst = sqlite3.connect('backup.db')
         with dst:
             src.backup(dst, pages=1, progress=progress)
         dst.close()
         src.close()

      Example 2, copy an existing database into a transient copy:

         src = sqlite3.connect('example.db')
         dst = sqlite3.connect(':memory:')
         src.backup(dst)

      Novo na versão 3.7.

      Ver também: How to handle non-UTF-8 text encodings

   getlimit(category, /)

      Get a connection runtime limit.

      Parâmetros:
         **category** (*int*) -- The SQLite limit category to be
         queried.

      Tipo de retorno:
         int

      Levanta:
         **ProgrammingError** -- If *category* is not recognised by
         the underlying SQLite library.

      Example, query the maximum length of an SQL statement for
      "Connection" "con" (the default is 1000000000):

         >>> con.getlimit(sqlite3.SQLITE_LIMIT_SQL_LENGTH)
         1000000000

      Novo na versão 3.11.

   setlimit(category, limit, /)

      Set a connection runtime limit. Attempts to increase a limit
      above its hard upper bound are silently truncated to the hard
      upper bound. Regardless of whether or not the limit was changed,
      the prior value of the limit is returned.

      Parâmetros:
         * **category** (*int*) -- The SQLite limit category to be
           set.

         * **limit** (*int*) -- The value of the new limit. If
           negative, the current limit is unchanged.

      Tipo de retorno:
         int

      Levanta:
         **ProgrammingError** -- If *category* is not recognised by
         the underlying SQLite library.

      Example, limit the number of attached databases to 1 for
      "Connection" "con" (the default limit is 10):

         >>> con.setlimit(sqlite3.SQLITE_LIMIT_ATTACHED, 1)
         10
         >>> con.getlimit(sqlite3.SQLITE_LIMIT_ATTACHED)
         1

      Novo na versão 3.11.

   getconfig(op, /)

      Query a boolean connection configuration option.

      Parâmetros:
         **op** (*int*) -- A SQLITE_DBCONFIG code.

      Tipo de retorno:
         bool

      Novo na versão 3.12.

   setconfig(op, enable=True, /)

      Set a boolean connection configuration option.

      Parâmetros:
         * **op** (*int*) -- A SQLITE_DBCONFIG code.

         * **enable** (*bool*) -- "True" if the configuration option
           should be enabled (default); "False" if it should be
           disabled.

      Novo na versão 3.12.

   serialize(*, name='main')

      Serialize a database into a "bytes" object.  For an ordinary on-
      disk database file, the serialization is just a copy of the disk
      file.  For an in-memory database or a "temp" database, the
      serialization is the same sequence of bytes which would be
      written to disk if that database were backed up to disk.

      Parâmetros:
         **name** (*str*) -- The database name to be serialized.
         Defaults to ""main"".

      Tipo de retorno:
         bytes

      Nota:

        This method is only available if the underlying SQLite library
        has the serialize API.

      Novo na versão 3.11.

   deserialize(data, /, *, name='main')

      Deserialize a "serialized" database into a "Connection". This
      method causes the database connection to disconnect from
      database *name*, and reopen *name* as an in-memory database
      based on the serialization contained in *data*.

      Parâmetros:
         * **data** (*bytes*) -- A serialized database.

         * **name** (*str*) -- The database name to deserialize into.
           Defaults to ""main"".

      Levanta:
         * **OperationalError** -- If the database connection is
           currently involved in a read transaction or a backup
           operation.

         * **DatabaseError** -- If *data* does not contain a valid
           SQLite database.

         * **OverflowError** -- If "len(data)" is larger than "2**63 -
           1".

      Nota:

        This method is only available if the underlying SQLite library
        has the deserialize API.

      Novo na versão 3.11.

   autocommit

      This attribute controls **PEP 249**-compliant transaction
      behaviour. "autocommit" has three allowed values:

      * "False": Select **PEP 249**-compliant transaction behaviour,
        implying that "sqlite3" ensures a transaction is always open.
        Use "commit()" and "rollback()" to close transactions.

        This is the recommended value of "autocommit".

      * "True": Use SQLite's autocommit mode. "commit()" and
        "rollback()" have no effect in this mode.

      * "LEGACY_TRANSACTION_CONTROL": Pre-Python 3.12 (non-**PEP
        249**-compliant) transaction control. See "isolation_level"
        for more details.

        This is currently the default value of "autocommit".

      Changing "autocommit" to "False" will open a new transaction,
      and changing it to "True" will commit any pending transaction.

      See Controle de transações através do atributo autocommit for
      more details.

      Nota:

        The "isolation_level" attribute has no effect unless
        "autocommit" is "LEGACY_TRANSACTION_CONTROL".

      Novo na versão 3.12.

   in_transaction

      This read-only attribute corresponds to the low-level SQLite
      autocommit mode.

      "True" if a transaction is active (there are uncommitted
      changes), "False" otherwise.

      Novo na versão 3.2.

   isolation_level

      Controls the legacy transaction handling mode of "sqlite3". If
      set to "None", transactions are never implicitly opened. If set
      to one of ""DEFERRED"", ""IMMEDIATE"", or ""EXCLUSIVE"",
      corresponding to the underlying SQLite transaction behaviour,
      implicit transaction management is performed.

      If not overridden by the *isolation_level* parameter of
      "connect()", the default is """", which is an alias for
      ""DEFERRED"".

      Nota:

        Using "autocommit" to control transaction handling is
        recommended over using "isolation_level". "isolation_level"
        has no effect unless "autocommit" is set to
        "LEGACY_TRANSACTION_CONTROL" (the default).

   row_factory

      The initial "row_factory" for "Cursor" objects created from this
      connection. Assigning to this attribute does not affect the
      "row_factory" of existing cursors belonging to this connection,
      only new ones. Is "None" by default, meaning each row is
      returned as a "tuple".

      See How to create and use row factories for more details.

   text_factory

      A *callable* that accepts a "bytes" parameter and returns a text
      representation of it. The callable is invoked for SQLite values
      with the "TEXT" data type. By default, this attribute is set to
      "str".

      See How to handle non-UTF-8 text encodings for more details.

   total_changes

      Return the total number of database rows that have been
      modified, inserted, or deleted since the database connection was
      opened.


Cursor objects
--------------

   A "Cursor" object represents a database cursor which is used to
   execute SQL statements, and manage the context of a fetch
   operation. Cursors are created using "Connection.cursor()", or by
   using any of the connection shortcut methods.

   Cursor objects are *iterators*, meaning that if you "execute()" a
   "SELECT" query, you can simply iterate over the cursor to fetch the
   resulting rows:

      for row in cur.execute("SELECT t FROM data"):
          print(row)

class sqlite3.Cursor

   A "Cursor" instance has the following attributes and methods.

   execute(sql, parameters=(), /)

      Execute a single SQL statement, optionally binding Python values
      using placeholders.

      Parâmetros:
         * **sql** (*str*) -- A single SQL statement.

         * **parameters** ("dict" | *sequence*) -- Python values to
           bind to placeholders in *sql*. A "dict" if named
           placeholders are used. A *sequence* if unnamed placeholders
           are used. See How to use placeholders to bind values in SQL
           queries.

      Levanta:
         **ProgrammingError** -- If *sql* contains more than one SQL
         statement.

      If "autocommit" is "LEGACY_TRANSACTION_CONTROL",
      "isolation_level" is not "None", *sql* is an "INSERT", "UPDATE",
      "DELETE", or "REPLACE" statement, and there is no open
      transaction, a transaction is implicitly opened before executing
      *sql*.

      Descontinuado desde a versão 3.12, será removido na versão 3.14:
      "DeprecationWarning" is emitted if named placeholders are used
      and *parameters* is a sequence instead of a "dict". Starting
      with Python 3.14, "ProgrammingError" will be raised instead.

      Use "executescript()" to execute multiple SQL statements.

   executemany(sql, parameters, /)

      For every item in *parameters*, repeatedly execute the
      parameterized DML (Data Manipulation Language) SQL statement
      *sql*.

      Uses the same implicit transaction handling as "execute()".

      Parâmetros:
         * **sql** (*str*) -- A single SQL DML statement.

         * **parameters** (*iterable*) -- An *iterable* of parameters
           to bind with the placeholders in *sql*. See How to use
           placeholders to bind values in SQL queries.

      Levanta:
         **ProgrammingError** -- If *sql* contains more than one SQL
         statement, or is not a DML statement.

      Exemplo:

         rows = [
             ("row1",),
             ("row2",),
         ]
         # cur is an sqlite3.Cursor object
         cur.executemany("INSERT INTO data VALUES(?)", rows)

      Nota:

        Any resulting rows are discarded, including DML statements
        with RETURNING clauses.

      Descontinuado desde a versão 3.12, será removido na versão 3.14:
      "DeprecationWarning" is emitted if named placeholders are used
      and the items in *parameters* are sequences instead of "dict"s.
      Starting with Python 3.14, "ProgrammingError" will be raised
      instead.

   executescript(sql_script, /)

      Execute the SQL statements in *sql_script*. If the "autocommit"
      is "LEGACY_TRANSACTION_CONTROL" and there is a pending
      transaction, an implicit "COMMIT" statement is executed first.
      No other implicit transaction control is performed; any
      transaction control must be added to *sql_script*.

      *sql_script* must be a "string".

      Exemplo:

         # cur is an sqlite3.Cursor object
         cur.executescript("""
             BEGIN;
             CREATE TABLE person(firstname, lastname, age);
             CREATE TABLE book(title, author, published);
             CREATE TABLE publisher(name, address);
             COMMIT;
         """)

   fetchone()

      If "row_factory" is "None", return the next row query result set
      as a "tuple". Else, pass it to the row factory and return its
      result. Return "None" if no more data is available.

   fetchmany(size=cursor.arraysize)

      Return the next set of rows of a query result as a "list".
      Return an empty list if no more rows are available.

      The number of rows to fetch per call is specified by the *size*
      parameter. If *size* is not given, "arraysize" determines the
      number of rows to be fetched. If fewer than *size* rows are
      available, as many rows as are available are returned.

      Note there are performance considerations involved with the
      *size* parameter. For optimal performance, it is usually best to
      use the arraysize attribute. If the *size* parameter is used,
      then it is best for it to retain the same value from one
      "fetchmany()" call to the next.

   fetchall()

      Return all (remaining) rows of a query result as a "list".
      Return an empty list if no rows are available. Note that the
      "arraysize" attribute can affect the performance of this
      operation.

   close()

      Close the cursor now (rather than whenever "__del__" is called).

      The cursor will be unusable from this point forward; a
      "ProgrammingError" exception will be raised if any operation is
      attempted with the cursor.

   setinputsizes(sizes, /)

      Required by the DB-API. Does nothing in "sqlite3".

   setoutputsize(size, column=None, /)

      Required by the DB-API. Does nothing in "sqlite3".

   arraysize

      Read/write attribute that controls the number of rows returned
      by "fetchmany()". The default value is 1 which means a single
      row would be fetched per call.

   connection

      Read-only attribute that provides the SQLite database
      "Connection" belonging to the cursor.  A "Cursor" object created
      by calling "con.cursor()" will have a "connection" attribute
      that refers to *con*:

         >>> con = sqlite3.connect(":memory:")
         >>> cur = con.cursor()
         >>> cur.connection == con
         True

   description

      Read-only attribute that provides the column names of the last
      query. To remain compatible with the Python DB API, it returns a
      7-tuple for each column where the last six items of each tuple
      are "None".

      It is set for "SELECT" statements without any matching rows as
      well.

   lastrowid

      Read-only attribute that provides the row id of the last
      inserted row. It is only updated after successful "INSERT" or
      "REPLACE" statements using the "execute()" method.  For other
      statements, after "executemany()" or "executescript()", or if
      the insertion failed, the value of "lastrowid" is left
      unchanged.  The initial value of "lastrowid" is "None".

      Nota:

        Inserts into "WITHOUT ROWID" tables are not recorded.

      Alterado na versão 3.6: Added support for the "REPLACE"
      statement.

   rowcount

      Read-only attribute that provides the number of modified rows
      for "INSERT", "UPDATE", "DELETE", and "REPLACE" statements; is
      "-1" for other statements, including CTE (Common Table
      Expression) queries. It is only updated by the "execute()" and
      "executemany()" methods, after the statement has run to
      completion. This means that any resulting rows must be fetched
      in order for "rowcount" to be updated.

   row_factory

      Control how a row fetched from this "Cursor" is represented. If
      "None", a row is represented as a "tuple". Can be set to the
      included "sqlite3.Row"; or a *callable* that accepts two
      arguments, a "Cursor" object and the "tuple" of row values, and
      returns a custom object representing an SQLite row.

      Defaults to what "Connection.row_factory" was set to when the
      "Cursor" was created. Assigning to this attribute does not
      affect "Connection.row_factory" of the parent connection.

      See How to create and use row factories for more details.


Row objects
-----------

class sqlite3.Row

   A "Row" instance serves as a highly optimized "row_factory" for
   "Connection" objects. It supports iteration, equality testing,
   "len()", and *mapping* access by column name and index.

   Two "Row" objects compare equal if they have identical column names
   and values.

   See How to create and use row factories for more details.

   keys()

      Return a "list" of column names as "strings". Immediately after
      a query, it is the first member of each tuple in
      "Cursor.description".

   Alterado na versão 3.5: Added support of slicing.


Blob objects
------------

class sqlite3.Blob

   Novo na versão 3.11.

   A "Blob" instance is a *file-like object* that can read and write
   data in an SQLite BLOB (Binary Large OBject). Call "len(blob)" to
   get the size (number of bytes) of the blob. Use indices and
   *slices* for direct access to the blob data.

   Use the "Blob" as a *context manager* to ensure that the blob
   handle is closed after use.

      con = sqlite3.connect(":memory:")
      con.execute("CREATE TABLE test(blob_col blob)")
      con.execute("INSERT INTO test(blob_col) VALUES(zeroblob(13))")

      # Write to our blob, using two write operations:
      with con.blobopen("test", "blob_col", 1) as blob:
          blob.write(b"hello, ")
          blob.write(b"world.")
          # Modify the first and last bytes of our blob
          blob[0] = ord("H")
          blob[-1] = ord("!")

      # Read the contents of our blob
      with con.blobopen("test", "blob_col", 1) as blob:
          greeting = blob.read()

      print(greeting)  # outputs "b'Hello, world!'"

   close()

      Close the blob.

      The blob will be unusable from this point onward.  An "Error"
      (or subclass) exception will be raised if any further operation
      is attempted with the blob.

   read(length=-1, /)

      Read *length* bytes of data from the blob at the current offset
      position. If the end of the blob is reached, the data up to EOF
      (End of File) will be returned.  When *length* is not specified,
      or is negative, "read()" will read until the end of the blob.

   write(data, /)

      Write *data* to the blob at the current offset.  This function
      cannot change the blob length.  Writing beyond the end of the
      blob will raise "ValueError".

   tell()

      Return the current access position of the blob.

   seek(offset, origin=os.SEEK_SET, /)

      Set the current access position of the blob to *offset*.  The
      *origin* argument defaults to "os.SEEK_SET" (absolute blob
      positioning). Other values for *origin* are "os.SEEK_CUR" (seek
      relative to the current position) and "os.SEEK_END" (seek
      relative to the blob’s end).


PrepareProtocol objects
-----------------------

class sqlite3.PrepareProtocol

   The PrepareProtocol type's single purpose is to act as a **PEP
   246** style adaption protocol for objects that can adapt themselves
   to native SQLite types.


Exceções
--------

The exception hierarchy is defined by the DB-API 2.0 (**PEP 249**).

exception sqlite3.Warning

   This exception is not currently raised by the "sqlite3" module, but
   may be raised by applications using "sqlite3", for example if a
   user-defined function truncates data while inserting. "Warning" is
   a subclass of "Exception".

exception sqlite3.Error

   The base class of the other exceptions in this module. Use this to
   catch all errors with one single "except" statement. "Error" is a
   subclass of "Exception".

   If the exception originated from within the SQLite library, the
   following two attributes are added to the exception:

   sqlite_errorcode

      The numeric error code from the SQLite API

      Novo na versão 3.11.

   sqlite_errorname

      The symbolic name of the numeric error code from the SQLite API

      Novo na versão 3.11.

exception sqlite3.InterfaceError

   Exception raised for misuse of the low-level SQLite C API. In other
   words, if this exception is raised, it probably indicates a bug in
   the "sqlite3" module. "InterfaceError" is a subclass of "Error".

exception sqlite3.DatabaseError

   Exception raised for errors that are related to the database. This
   serves as the base exception for several types of database errors.
   It is only raised implicitly through the specialised subclasses.
   "DatabaseError" is a subclass of "Error".

exception sqlite3.DataError

   Exception raised for errors caused by problems with the processed
   data, like numeric values out of range, and strings which are too
   long. "DataError" is a subclass of "DatabaseError".

exception sqlite3.OperationalError

   Exception raised for errors that are related to the database's
   operation, and not necessarily under the control of the programmer.
   For example, the database path is not found, or a transaction could
   not be processed. "OperationalError" is a subclass of
   "DatabaseError".

exception sqlite3.IntegrityError

   Exception raised when the relational integrity of the database is
   affected, e.g. a foreign key check fails.  It is a subclass of
   "DatabaseError".

exception sqlite3.InternalError

   Exception raised when SQLite encounters an internal error. If this
   is raised, it may indicate that there is a problem with the runtime
   SQLite library. "InternalError" is a subclass of "DatabaseError".

exception sqlite3.ProgrammingError

   Exception raised for "sqlite3" API programming errors, for example
   supplying the wrong number of bindings to a query, or trying to
   operate on a closed "Connection". "ProgrammingError" is a subclass
   of "DatabaseError".

exception sqlite3.NotSupportedError

   Exception raised in case a method or database API is not supported
   by the underlying SQLite library. For example, setting
   *deterministic* to "True" in "create_function()", if the underlying
   SQLite library does not support deterministic functions.
   "NotSupportedError" is a subclass of "DatabaseError".


SQLite and Python types
-----------------------

SQLite natively supports the following types: "NULL", "INTEGER",
"REAL", "TEXT", "BLOB".

The following Python types can thus be sent to SQLite without any
problem:

+---------------------------------+---------------+
| Tipo Python                     | Tipo SQLite   |
|=================================|===============|
| "None"                          | "NULL"        |
+---------------------------------+---------------+
| "int"                           | "INTEGER"     |
+---------------------------------+---------------+
| "float"                         | "REAL"        |
+---------------------------------+---------------+
| "str"                           | "TEXT"        |
+---------------------------------+---------------+
| "bytes"                         | "BLOB"        |
+---------------------------------+---------------+

This is how SQLite types are converted to Python types by default:

+---------------+------------------------------------------------+
| Tipo SQLite   | Tipo Python                                    |
|===============|================================================|
| "NULL"        | "None"                                         |
+---------------+------------------------------------------------+
| "INTEGER"     | "int"                                          |
+---------------+------------------------------------------------+
| "REAL"        | "float"                                        |
+---------------+------------------------------------------------+
| "TEXT"        | depends on "text_factory", "str" by default    |
+---------------+------------------------------------------------+
| "BLOB"        | "bytes"                                        |
+---------------+------------------------------------------------+

The type system of the "sqlite3" module is extensible in two ways: you
can store additional Python types in an SQLite database via object
adapters, and you can let the "sqlite3" module convert SQLite types to
Python types via converters.


Default adapters and converters (deprecated)
--------------------------------------------

Nota:

  The default adapters and converters are deprecated as of Python
  3.12. Instead, use the Adapter and converter recipes and tailor them
  to your needs.

The deprecated default adapters and converters consist of:

* An adapter for "datetime.date" objects to "strings" in ISO 8601
  format.

* An adapter for "datetime.datetime" objects to strings in ISO 8601
  format.

* A converter for declared "date" types to "datetime.date" objects.

* A converter for declared "timestamp" types to "datetime.datetime"
  objects. Fractional parts will be truncated to 6 digits (microsecond
  precision).

Nota:

  The default "timestamp" converter ignores UTC offsets in the
  database and always returns a naive "datetime.datetime" object. To
  preserve UTC offsets in timestamps, either leave converters
  disabled, or register an offset-aware converter with
  "register_converter()".

Obsoleto desde a versão 3.12.


Command-line interface
----------------------

The "sqlite3" module can be invoked as a script, using the
interpreter's "-m" switch, in order to provide a simple SQLite shell.
The argument signature is as follows:

   python -m sqlite3 [-h] [-v] [filename] [sql]

Type ".quit" or CTRL-D to exit the shell.

-h, --help

   Print CLI help.

-v, --version

   Print underlying SQLite library version.

Novo na versão 3.12.


Guias de como fazer
===================


How to use placeholders to bind values in SQL queries
-----------------------------------------------------

SQL operations usually need to use values from Python variables.
However, beware of using Python's string operations to assemble
queries, as they are vulnerable to SQL injection attacks. For example,
an attacker can simply close the single quote and inject "OR TRUE" to
select all rows:

   >>> # Never do this -- insecure!
   >>> symbol = input()
   ' OR TRUE; --
   >>> sql = "SELECT * FROM stocks WHERE symbol = '%s'" % symbol
   >>> print(sql)
   SELECT * FROM stocks WHERE symbol = '' OR TRUE; --'
   >>> cur.execute(sql)

Instead, use the DB-API's parameter substitution. To insert a variable
into a query string, use a placeholder in the string, and substitute
the actual values into the query by providing them as a "tuple" of
values to the second argument of the cursor's "execute()" method.

An SQL statement may use one of two kinds of placeholders: question
marks (qmark style) or named placeholders (named style). For the qmark
style, *parameters* must be a *sequence* whose length must match the
number of placeholders, or a "ProgrammingError" is raised. For the
named style, *parameters* must be an instance of a "dict" (or a
subclass), which must contain keys for all named parameters; any extra
items are ignored. Here's an example of both styles:

   con = sqlite3.connect(":memory:")
   cur = con.execute("CREATE TABLE lang(name, first_appeared)")

   # This is the named style used with executemany():
   data = (
       {"name": "C", "year": 1972},
       {"name": "Fortran", "year": 1957},
       {"name": "Python", "year": 1991},
       {"name": "Go", "year": 2009},
   )
   cur.executemany("INSERT INTO lang VALUES(:name, :year)", data)

   # This is the qmark style used in a SELECT query:
   params = (1972,)
   cur.execute("SELECT * FROM lang WHERE first_appeared = ?", params)
   print(cur.fetchall())

Nota:

  **PEP 249** numeric placeholders are *not* supported. If used, they
  will be interpreted as named placeholders.


How to adapt custom Python types to SQLite values
-------------------------------------------------

SQLite supports only a limited set of data types natively. To store
custom Python types in SQLite databases, *adapt* them to one of the
Python types SQLite natively understands.

There are two ways to adapt Python objects to SQLite types: letting
your object adapt itself, or using an *adapter callable*. The latter
will take precedence above the former. For a library that exports a
custom type, it may make sense to enable that type to adapt itself. As
an application developer, it may make more sense to take direct
control by registering custom adapter functions.


How to write adaptable objects
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Suppose we have a "Point" class that represents a pair of coordinates,
"x" and "y", in a Cartesian coordinate system. The coordinate pair
will be stored as a text string in the database, using a semicolon to
separate the coordinates. This can be implemented by adding a
"__conform__(self, protocol)" method which returns the adapted value.
The object passed to *protocol* will be of type "PrepareProtocol".

   class Point:
       def __init__(self, x, y):
           self.x, self.y = x, y

       def __conform__(self, protocol):
           if protocol is sqlite3.PrepareProtocol:
               return f"{self.x};{self.y}"

   con = sqlite3.connect(":memory:")
   cur = con.cursor()

   cur.execute("SELECT ?", (Point(4.0, -3.2),))
   print(cur.fetchone()[0])


How to register adapter callables
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The other possibility is to create a function that converts the Python
object to an SQLite-compatible type. This function can then be
registered using "register_adapter()".

   class Point:
       def __init__(self, x, y):
           self.x, self.y = x, y

   def adapt_point(point):
       return f"{point.x};{point.y}"

   sqlite3.register_adapter(Point, adapt_point)

   con = sqlite3.connect(":memory:")
   cur = con.cursor()

   cur.execute("SELECT ?", (Point(1.0, 2.5),))
   print(cur.fetchone()[0])


How to convert SQLite values to custom Python types
---------------------------------------------------

Writing an adapter lets you convert *from* custom Python types *to*
SQLite values. To be able to convert *from* SQLite values *to* custom
Python types, we use *converters*.

Let's go back to the "Point" class. We stored the x and y coordinates
separated via semicolons as strings in SQLite.

First, we'll define a converter function that accepts the string as a
parameter and constructs a "Point" object from it.

Nota:

  Converter functions are **always** passed a "bytes" object, no
  matter the underlying SQLite data type.

   def convert_point(s):
       x, y = map(float, s.split(b";"))
       return Point(x, y)

We now need to tell "sqlite3" when it should convert a given SQLite
value. This is done when connecting to a database, using the
*detect_types* parameter of "connect()". There are three options:

* Implicit: set *detect_types* to "PARSE_DECLTYPES"

* Explicit: set *detect_types* to "PARSE_COLNAMES"

* Both: set *detect_types* to "sqlite3.PARSE_DECLTYPES |
  sqlite3.PARSE_COLNAMES". Column names take precedence over declared
  types.

The following example illustrates the implicit and explicit
approaches:

   class Point:
       def __init__(self, x, y):
           self.x, self.y = x, y

       def __repr__(self):
           return f"Point({self.x}, {self.y})"

   def adapt_point(point):
       return f"{point.x};{point.y}"

   def convert_point(s):
       x, y = list(map(float, s.split(b";")))
       return Point(x, y)

   # Register the adapter and converter
   sqlite3.register_adapter(Point, adapt_point)
   sqlite3.register_converter("point", convert_point)

   # 1) Parse using declared types
   p = Point(4.0, -3.2)
   con = sqlite3.connect(":memory:", detect_types=sqlite3.PARSE_DECLTYPES)
   cur = con.execute("CREATE TABLE test(p point)")

   cur.execute("INSERT INTO test(p) VALUES(?)", (p,))
   cur.execute("SELECT p FROM test")
   print("with declared types:", cur.fetchone()[0])
   cur.close()
   con.close()

   # 2) Parse using column names
   con = sqlite3.connect(":memory:", detect_types=sqlite3.PARSE_COLNAMES)
   cur = con.execute("CREATE TABLE test(p)")

   cur.execute("INSERT INTO test(p) VALUES(?)", (p,))
   cur.execute('SELECT p AS "p [point]" FROM test')
   print("with column names:", cur.fetchone()[0])


Adapter and converter recipes
-----------------------------

This section shows recipes for common adapters and converters.

   import datetime
   import sqlite3

   def adapt_date_iso(val):
       """Adapt datetime.date to ISO 8601 date."""
       return val.isoformat()

   def adapt_datetime_iso(val):
       """Adapt datetime.datetime to timezone-naive ISO 8601 date."""
       return val.isoformat()

   def adapt_datetime_epoch(val):
       """Adapt datetime.datetime to Unix timestamp."""
       return int(val.timestamp())

   sqlite3.register_adapter(datetime.date, adapt_date_iso)
   sqlite3.register_adapter(datetime.datetime, adapt_datetime_iso)
   sqlite3.register_adapter(datetime.datetime, adapt_datetime_epoch)

   def convert_date(val):
       """Convert ISO 8601 date to datetime.date object."""
       return datetime.date.fromisoformat(val.decode())

   def convert_datetime(val):
       """Convert ISO 8601 datetime to datetime.datetime object."""
       return datetime.datetime.fromisoformat(val.decode())

   def convert_timestamp(val):
       """Convert Unix epoch timestamp to datetime.datetime object."""
       return datetime.datetime.fromtimestamp(int(val))

   sqlite3.register_converter("date", convert_date)
   sqlite3.register_converter("datetime", convert_datetime)
   sqlite3.register_converter("timestamp", convert_timestamp)


How to use connection shortcut methods
--------------------------------------

Using the "execute()", "executemany()", and "executescript()" methods
of the "Connection" class, your code can be written more concisely
because you don't have to create the (often superfluous) "Cursor"
objects explicitly. Instead, the "Cursor" objects are created
implicitly and these shortcut methods return the cursor objects. This
way, you can execute a "SELECT" statement and iterate over it directly
using only a single call on the "Connection" object.

   # Create and fill the table.
   con = sqlite3.connect(":memory:")
   con.execute("CREATE TABLE lang(name, first_appeared)")
   data = [
       ("C++", 1985),
       ("Objective-C", 1984),
   ]
   con.executemany("INSERT INTO lang(name, first_appeared) VALUES(?, ?)", data)

   # Print the table contents
   for row in con.execute("SELECT name, first_appeared FROM lang"):
       print(row)

   print("I just deleted", con.execute("DELETE FROM lang").rowcount, "rows")

   # close() is not a shortcut method and it's not called automatically;
   # the connection object should be closed manually
   con.close()


How to use the connection context manager
-----------------------------------------

A "Connection" object can be used as a context manager that
automatically commits or rolls back open transactions when leaving the
body of the context manager. If the body of the "with" statement
finishes without exceptions, the transaction is committed. If this
commit fails, or if the body of the "with" statement raises an
uncaught exception, the transaction is rolled back. If "autocommit" is
"False", a new transaction is implicitly opened after committing or
rolling back.

If there is no open transaction upon leaving the body of the "with"
statement, or if "autocommit" is "True", the context manager does
nothing.

Nota:

  The context manager neither implicitly opens a new transaction nor
  closes the connection. If you need a closing context manager,
  consider using "contextlib.closing()".

   con = sqlite3.connect(":memory:")
   con.execute("CREATE TABLE lang(id INTEGER PRIMARY KEY, name VARCHAR UNIQUE)")

   # Successful, con.commit() is called automatically afterwards
   with con:
       con.execute("INSERT INTO lang(name) VALUES(?)", ("Python",))

   # con.rollback() is called after the with block finishes with an exception,
   # the exception is still raised and must be caught
   try:
       with con:
           con.execute("INSERT INTO lang(name) VALUES(?)", ("Python",))
   except sqlite3.IntegrityError:
       print("couldn't add Python twice")

   # Connection object used as context manager only commits or rollbacks transactions,
   # so the connection object should be closed manually
   con.close()


How to work with SQLite URIs
----------------------------

Some useful URI tricks include:

* Open a database in read-only mode:

   >>> con = sqlite3.connect("file:tutorial.db?mode=ro", uri=True)
   >>> con.execute("CREATE TABLE readonly(data)")
   Traceback (most recent call last):
   OperationalError: attempt to write a readonly database

* Do not implicitly create a new database file if it does not already
  exist; will raise "OperationalError" if unable to create a new file:

   >>> con = sqlite3.connect("file:nosuchdb.db?mode=rw", uri=True)
   Traceback (most recent call last):
   OperationalError: unable to open database file

* Create a shared named in-memory database:

   db = "file:mem1?mode=memory&cache=shared"
   con1 = sqlite3.connect(db, uri=True)
   con2 = sqlite3.connect(db, uri=True)
   with con1:
       con1.execute("CREATE TABLE shared(data)")
       con1.execute("INSERT INTO shared VALUES(28)")
   res = con2.execute("SELECT data FROM shared")
   assert res.fetchone() == (28,)

More information about this feature, including a list of parameters,
can be found in the SQLite URI documentation.


How to create and use row factories
-----------------------------------

By default, "sqlite3" represents each row as a "tuple". If a "tuple"
does not suit your needs, you can use the "sqlite3.Row" class or a
custom "row_factory".

While "row_factory" exists as an attribute both on the "Cursor" and
the "Connection", it is recommended to set "Connection.row_factory",
so all cursors created from the connection will use the same row
factory.

"Row" provides indexed and case-insensitive named access to columns,
with minimal memory overhead and performance impact over a "tuple". To
use "Row" as a row factory, assign it to the "row_factory" attribute:

   >>> con = sqlite3.connect(":memory:")
   >>> con.row_factory = sqlite3.Row

Queries now return "Row" objects:

   >>> res = con.execute("SELECT 'Earth' AS name, 6378 AS radius")
   >>> row = res.fetchone()
   >>> row.keys()
   ['name', 'radius']
   >>> row[0]         # Access by index.
   'Earth'
   >>> row["name"]    # Access by name.
   'Earth'
   >>> row["RADIUS"]  # Column names are case-insensitive.
   6378

Nota:

  The "FROM" clause can be omitted in the "SELECT" statement, as in
  the above example. In such cases, SQLite returns a single row with
  columns defined by expressions, e.g. literals, with the given
  aliases "expr AS alias".

You can create a custom "row_factory" that returns each row as a
"dict", with column names mapped to values:

   def dict_factory(cursor, row):
       fields = [column[0] for column in cursor.description]
       return {key: value for key, value in zip(fields, row)}

Using it, queries now return a "dict" instead of a "tuple":

   >>> con = sqlite3.connect(":memory:")
   >>> con.row_factory = dict_factory
   >>> for row in con.execute("SELECT 1 AS a, 2 AS b"):
   ...     print(row)
   {'a': 1, 'b': 2}

The following row factory returns a *named tuple*:

   from collections import namedtuple

   def namedtuple_factory(cursor, row):
       fields = [column[0] for column in cursor.description]
       cls = namedtuple("Row", fields)
       return cls._make(row)

"namedtuple_factory()" can be used as follows:

   >>> con = sqlite3.connect(":memory:")
   >>> con.row_factory = namedtuple_factory
   >>> cur = con.execute("SELECT 1 AS a, 2 AS b")
   >>> row = cur.fetchone()
   >>> row
   Row(a=1, b=2)
   >>> row[0]  # Indexed access.
   1
   >>> row.b   # Attribute access.
   2

With some adjustments, the above recipe can be adapted to use a
"dataclass", or any other custom class, instead of a "namedtuple".


How to handle non-UTF-8 text encodings
--------------------------------------

By default, "sqlite3" uses "str" to adapt SQLite values with the
"TEXT" data type. This works well for UTF-8 encoded text, but it might
fail for other encodings and invalid UTF-8. You can use a custom
"text_factory" to handle such cases.

Because of SQLite's flexible typing, it is not uncommon to encounter
table columns with the "TEXT" data type containing non-UTF-8
encodings, or even arbitrary data. To demonstrate, let's assume we
have a database with ISO-8859-2 (Latin-2) encoded text, for example a
table of Czech-English dictionary entries. Assuming we now have a
"Connection" instance "con" connected to this database, we can decode
the Latin-2 encoded text using this "text_factory":

   con.text_factory = lambda data: str(data, encoding="latin2")

For invalid UTF-8 or arbitrary data in stored in "TEXT" table columns,
you can use the following technique, borrowed from the Unicode HOWTO:

   con.text_factory = lambda data: str(data, errors="surrogateescape")

Nota:

  The "sqlite3" module API does not support strings containing
  surrogates.

Ver também: Unicode HOWTO


Explicação
==========


Controle de transações
----------------------

"sqlite3" oferece vários métodos para controlar se, quando e como as
transações do banco de dados são abertas e fechadas. Controle de
transações através do atributo autocommit é recomendado, enquanto
Controle de transação através do atributo isolation_level mantém o
comportamento pré-Python 3.12.


Controle de transações através do atributo "autocommit"
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

A forma recomendada de controlar o comportamento da transação é
através do atributo "Connection.autocommit", que deve ser
preferencialmente definido usando o parâmetro *autocommit* de
"connect()".

É sugerido definir *autocommit* como "False", o que implica controle
de transação compatível com a **PEP 249**. Isso significa:

* "sqlite3" garante que uma transação esteja sempre aberta, então
  "connect()", "Connection.commit()" e "Connection.rollback()" abrirão
  implicitamente uma nova transação (imediatamente após fechando a
  pendência, para as duas últimas). "sqlite3" usa instruções "BEGIN
  DEFERRED" ao abrir transações.

* Transações devem ser executadas explicitamente usando "commit()".

* Transações devem ser revertidas explicitamente usando "rollback()".

* Uma reversão implícita é executada se o banco de dados estiver em
  estado "close()" com alterações pendentes.

Defina *autocommit* como "True" para ativar o modo autocommit do
SQLite. Neste modo, "Connection.commit()" e "Connection.rollback()"
não têm efeito. Observe que o modo autocommit do SQLite é distinto do
atributo "Connection.autocommit" compatível com **PEP 249**; use
"Connection.in_transaction" para consultar o modo de confirmação
automática do SQLite de baixo nível.

Defina *autocommit* como "LEGACY_TRANSACTION_CONTROL" para deixar o
comportamento de controle de transação para o atributo
"Connection.isolation_level". Veja Controle de transação através do
atributo isolation_level para mais informações.


Controle de transação através do atributo "isolation_level"
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Nota:

  A forma recomendada de controlar transações é através do atributo
  "autocommit". Veja Controle de transações através do atributo
  autocommit.

Se "Connection.autocommit" estiver definido como
"LEGACY_TRANSACTION_CONTROL" (o padrão), o comportamento da transação
é controlado usando o atributo "Connection.isolation_level". Caso
contrário, "isolation_level" não tem efeito.

Se o atributo de conexão "isolation_level" não for "None", novas
transações são abertas implicitamente antes de "execute()" e
"executemany()" executa instruções "INSERT", "UPDATE", "DELETE" ou
"REPLACE"; para outras instruções, nenhuma manipulação de transação
implícita é executada. Use os métodos "commit()" e "rollback()" para
fazer commit e reverter respectivamente transações pendentes. Você
pode escolher o comportamento subjacente de transação do SQLite --
isto é, se e que tipo de instruções "BEGIN" do "sqlite3" são
executadas implicitamente -- através do atributo "isolation_level".

Se "isolation_level" estiver definido como "None", nenhuma transação
será aberta implicitamente. Isso deixa a biblioteca SQLite subjacente
no modo autocommit, mas também permite que o usuário execute sua
própria manipulação de transações usando instruções SQL explícitas. O
modo de autocommit da biblioteca SQLite subjacente pode ser consultado
usando o atributo "in_transaction".

O método "executescript()" compromete implicitamente qualquer
transação pendente antes da execução do script SQL fornecido,
independentemente do valor de "isolation_level".

Alterado na versão 3.6: "sqlite3" costumava fazer commit de forma
implícita de uma transação aberta antes das instruções DDL. Este não é
mais o caso.

Alterado na versão 3.12: A forma recomendada de controlar transações
agora é através do atributo "autocommit".
